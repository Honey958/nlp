{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___\n",
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mary': 1,\n",
       " 'discarded': 2,\n",
       " 'no': 3,\n",
       " 'the': 4,\n",
       " 'travelled': 5,\n",
       " 'bedroom': 6,\n",
       " 'went': 7,\n",
       " 'got': 8,\n",
       " 'journeyed': 9,\n",
       " 'hallway': 10,\n",
       " 'up': 11,\n",
       " 'left': 12,\n",
       " 'milk': 13,\n",
       " '.': 14,\n",
       " 'garden': 15,\n",
       " 'back': 16,\n",
       " 'took': 17,\n",
       " 'to': 18,\n",
       " 'sandra': 19,\n",
       " 'dropped': 20,\n",
       " 'daniel': 21,\n",
       " 'kitchen': 22,\n",
       " 'john': 23,\n",
       " 'apple': 24,\n",
       " 'football': 25,\n",
       " 'in': 26,\n",
       " 'is': 27,\n",
       " 'grabbed': 28,\n",
       " 'there': 29,\n",
       " 'down': 30,\n",
       " 'office': 31,\n",
       " 'yes': 32,\n",
       " '?': 33,\n",
       " 'picked': 34,\n",
       " 'bathroom': 35,\n",
       " 'put': 36,\n",
       " 'moved': 37}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  4,  6, 14],\n",
       "       [ 0,  0,  0, ...,  4, 15, 14],\n",
       "       [ 0,  0,  0, ...,  4, 15, 14],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  4, 24, 14],\n",
       "       [ 0,  0,  0, ...,  4, 15, 14],\n",
       "       [ 0,  0,  0, ..., 24, 29, 14]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 23, 26,  4, 22, 33],\n",
       "       [27, 23, 26,  4, 22, 33],\n",
       "       [27, 23, 26,  4, 15, 33],\n",
       "       ...,\n",
       "       [27,  1, 26,  4,  6, 33],\n",
       "       [27, 19, 26,  4, 15, 33],\n",
       "       [27,  1, 26,  4, 15, 33]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from tensorflow.keras.layers import add, dot, concatenate\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate/concat:0' shape=(None, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (lstm_3/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-c5e7f6f22a45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Reduce with RNN (LSTM)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (samples, 32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    926\u001b[0m                                                 input_list)\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1115\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m               \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[1;31m# LSTM does not support constants. Ignore it during process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1108\u001b[1;33m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    643\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m       init_state = get_initial_state_fn(\n\u001b[0m\u001b[0;32m    646\u001b[0m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[0;32m    647\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2522\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2523\u001b[1;33m     return list(_generate_zero_filled_state_for_cell(\n\u001b[0m\u001b[0;32m   2524\u001b[0m         self, inputs, batch_size, dtype))\n\u001b[0;32m   2525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2966\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2967\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2968\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   2982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2983\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2984\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2985\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2986\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   2979\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2980\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2981\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2983\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2746\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2747\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2748\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2749\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2792\u001b[0m           \u001b[1;31m# Create a constant if it won't be very big. Otherwise create a fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2793\u001b[0m           \u001b[1;31m# op to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2794\u001b[1;33m           \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2795\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2796\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2730\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2731\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2732\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2733\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2734\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   3028\u001b[0m         \u001b[0mbut\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresulting\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcast\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnecessary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m     \u001b[0mReturns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m     \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m     \u001b[0mcumprod\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m     raise NotImplementedError(\n\u001b[0m\u001b[0;32m    846\u001b[0m         \u001b[1;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m         \u001b[1;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (lstm_3/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, None, 64)     2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 156, 6)       0           sequential[0][0]                 \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
      "                                                                 sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 6, 220)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6, 38)        8398        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 6, 38)        0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 13,490\n",
      "Trainable params: 13,490\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:748 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 38) and (None, 6, 38) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-52a18c2bd74c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueries_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueries_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:748 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 38) and (None, 6, 38) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.19.5 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.19.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9999999\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.97079676\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
